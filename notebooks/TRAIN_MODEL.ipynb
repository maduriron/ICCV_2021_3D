{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL IMPORTS AND PARAMETERS ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "from models_scripts import i3_res50, i3_res50_nl, disable_bn, enable_bn\n",
    "from utilities_scripts import SAM, LR_Scheduler, get_criterion, LoadingBar, Log, initialize, RandAugment\n",
    "from dataset_scripts import CTDataset\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "cuda_device_index = 0\n",
    "rho = 0.05\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.005\n",
    "warmup_epochs = 5\n",
    "epochs = 100\n",
    "n_class = 2 # extend number of classes\n",
    "fold_id = \"1\" #the current fold running\n",
    "root = \"/home/sentic/storage2/iccv_madu/fold_1\"\n",
    "num_workers = 2 # workers for dataloader\n",
    "fold_train_path = \"./train_folding.json\"\n",
    "fold_valid_path = \"./valid_folding.json\"\n",
    "checkpoint_dir = \"/home/sentic/storage2/iccv_madu/checkpoints/\"\n",
    "# checkpoint_dir = \"/home/sentic/Documents/data/storage2/LEUKEMIA/C-NMC_Leukemia/checkpoints/\"\n",
    "device = torch.device(\"cuda:\" + str(cuda_device_index) if torch.cuda.is_available() else \"cpu\")\n",
    "prepath = \"\"\n",
    "# replacer = \"/home/sentic/Documents/data/storage2/LEUKEMIA/C-NMC_Leukemia\"\n",
    "replacer = \"\"\n",
    "clip_len = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL STUFF ###\n",
    "#### I) ResNet50_3D_NL ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I3Res50(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool1): MaxPool3d(kernel_size=(2, 3, 3), stride=(2, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "  (maxpool2): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(256, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (nl): NonLocalBlock(\n",
       "        (theta): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (maxpool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "        (phi): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (g): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (out): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (nl): NonLocalBlock(\n",
       "        (theta): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (maxpool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "        (phi): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (g): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (out): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (nl): NonLocalBlock(\n",
       "        (theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (maxpool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "        (phi): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (g): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (out): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (nl): NonLocalBlock(\n",
       "        (theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (maxpool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "        (phi): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (g): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (out): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (nl): NonLocalBlock(\n",
       "        (theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (maxpool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "        (phi): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (g): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (out): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained = None\n",
    "\n",
    "model = i3_res50_nl(n_class)\n",
    "\n",
    "if pretrained is not None:\n",
    "    model.load_state_dict(torch.load(pretrained, map_location='cuda:' + str(cuda_device_index)))\n",
    "\n",
    "\n",
    "######################\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET STUFF ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fold_train_path) as fhandle:\n",
    "    fold_splitter_train = json.load(fhandle)\n",
    "    \n",
    "with open(fold_valid_path) as fhandle:\n",
    "    fold_splitter_valid = json.load(fhandle)\n",
    "    \n",
    "dataset_train = CTDataset(root=root, \n",
    "                      fold_id=fold_id, \n",
    "                      fold_splitter=fold_splitter_train,\n",
    "                      transforms=None,\n",
    "                      replacer=\"\",\n",
    "                      prepath=\"\",\n",
    "                      clip_len=clip_len,\n",
    "                      split=\"train\"\n",
    "                      )\n",
    "\n",
    "dataset_valid = CTDataset(root=root, \n",
    "                      fold_id=fold_id, \n",
    "                      fold_splitter=fold_splitter_valid,\n",
    "                      transforms=None,\n",
    "                      replacer=\"\",\n",
    "                      prepath=\"\",\n",
    "                      clip_len=clip_len,\n",
    "                      split=\"val\"\n",
    "                      )\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=1, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKPOINTING MODEL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECKPOINTING ###\n",
    "#checkpoint = \"/home/sentic/storage2/iccv_madu/checkpoints/checkpoint_model1_1_17.pth\"\n",
    "checkpoint = None\n",
    "\n",
    "epoch_checkpoint = None\n",
    "net_state_dict = None\n",
    "optimizer_state_dict = None\n",
    "\n",
    "if checkpoint is not None:\n",
    "    dict_checkpoint = torch.load(checkpoint)\n",
    "    epoch_checkpoint = dict_checkpoint['epoch'] + 1\n",
    "    net_state_dict = dict_checkpoint['model_state_dict']\n",
    "    optimizer_state_dict = dict_checkpoint['optimizer_state_dict']\n",
    "    print(\"Initializing from checkpoint\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "if net_state_dict is not None:\n",
    "    model.load_state_dict(net_state_dict)\n",
    "    print(\"Loading model weights from checkpoint\")\n",
    "    \n",
    "if epoch_checkpoint is not None:\n",
    "    if epoch_checkpoint > warmup_epochs:\n",
    "        warmup_epochs = 0\n",
    "    else:\n",
    "        warmup_epochs = warmup_epochs - epoch_checkpoint\n",
    "    print(\"Setting warmup_epochs to {}\".format(warmup_epochs))\n",
    "\n",
    "if epoch_checkpoint is None:\n",
    "    epoch_checkpoint = 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTILS STUFF ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_optimizer = torch.optim.SGD\n",
    "optimizer = SAM(model.parameters(), base_optimizer, rho=rho, lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "if optimizer_state_dict is not None:\n",
    "    optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "scheduler = LR_Scheduler('cos',\n",
    "                        base_lr=learning_rate,\n",
    "                        num_epochs=epochs - epoch_checkpoint,\n",
    "                        iters_per_epoch=len(dataloader_train),\n",
    "                        warmup_epochs=warmup_epochs)\n",
    "\n",
    "criterion = get_criterion(smooth=0.1)\n",
    "log = Log(log_each=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN LOOP with CHECKPOINTING OPTIMIZER ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from epoch 0\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━╸T╺╸R╺╸A╺╸I╺╸N╺━━━━━━━┳━━━━━━━╸S╺╸T╺╸A╺╸T╺╸S╺━━━━━━━┳━━━━━━━╸V╺╸A╺╸L╺╸I╺╸D╺━━━━━━━┓\n",
      "┃              ┃              ╷              ┃              ╷              ┃              ╷              ┃\n",
      "┃       epoch  ┃        loss  │    accuracy  ┃        l.r.  │     elapsed  ┃        loss  │    accuracy  ┃\n",
      "┠──────────────╂──────────────┼──────────────╂──────────────┼──────────────╂──────────────┼──────────────┨\n",
      "\n",
      "┃           0  ┃      0.3508  │     51.57 %  ┃   1.997e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.6839  │     59.42 %  ┃\n",
      "┃           1  ┃      0.3412  │     56.40 %  ┃   3.997e-04  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.6813  │     62.30 %  ┃\n",
      "┃           2  ┃      0.3425  │     55.66 %  ┃   5.997e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.6836  │     56.02 %  ┃\n",
      "┃           3  ┃      0.3438  │     55.19 %  ┃   7.997e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.6846  │     56.02 %  ┃\n",
      "┃           4  ┃      0.3440  │     55.19 %  ┃   9.997e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.6847  │     56.02 %  ┃\n",
      "┃           5  ┃      0.3443  │     55.19 %  ┃   9.997e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.6853  │     56.02 %  ┃\n",
      "┃           6  ┃      0.3444  │     55.19 %  ┃   9.989e-04  │   12:51 min  ┃┈██████████████████████████▓┈┨      0.6845  │     56.02 %  ┃\n",
      "┃           7  ┃      0.3444  │     55.19 %  ┃   9.975e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.6869  │     54.71 %  ┃\n",
      "┃           8  ┃      0.3444  │     55.19 %  ┃   9.956e-04  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.6857  │     56.02 %  ┃\n",
      "┃           9  ┃      0.3443  │     55.19 %  ┃   9.932e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.6852  │     56.02 %  ┃\n",
      "┃          10  ┃      0.3442  │     55.19 %  ┃   9.902e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.6847  │     56.02 %  ┃\n",
      "┃          11  ┃      0.3439  │     55.19 %  ┃   9.867e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.6857  │     56.02 %  ┃\n",
      "┃          12  ┃      0.3441  │     55.19 %  ┃   9.826e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.6848  │     54.97 %  ┃\n",
      "┃          13  ┃      0.3437  │     55.19 %  ┃   9.780e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.6844  │     56.02 %  ┃\n",
      "┃          14  ┃      0.3434  │     55.19 %  ┃   9.729e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.7131  │     39.27 %  ┃\n",
      "┃          15  ┃      0.3419  │     55.39 %  ┃   9.673e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.6813  │     56.28 %  ┃\n",
      "┃          16  ┃      0.3373  │     60.48 %  ┃   9.612e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.6805  │     60.99 %  ┃\n",
      "┃          17  ┃      0.3332  │     62.83 %  ┃   9.545e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.6532  │     67.54 %  ┃\n",
      "┃          18  ┃      0.3228  │     69.66 %  ┃   9.474e-04  │   12:51 min  ┃┈██████████████████████████▓┈┨      0.6005  │     73.56 %  ┃\n",
      "┃          19  ┃      0.3120  │     71.06 %  ┃   9.397e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.5606  │     77.75 %  ┃\n",
      "┃          20  ┃      0.2984  │     73.88 %  ┃   9.316e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.5363  │     79.06 %  ┃\n",
      "┃          21  ┃      0.2873  │     76.83 %  ┃   9.231e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.5308  │     79.58 %  ┃\n",
      "┃          22  ┃      0.2737  │     79.71 %  ┃   9.140e-04  │   12:51 min  ┃┈██████████████████████████▓┈┨      0.4966  │     80.89 %  ┃\n",
      "┃          23  ┃      0.2593  │     82.12 %  ┃   9.045e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.4733  │     82.98 %  ┃\n",
      "┃          24  ┃      0.2492  │     81.51 %  ┃   8.946e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.4509  │     85.08 %  ┃\n",
      "┃          25  ┃      0.2370  │     84.39 %  ┃   8.842e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.4501  │     84.55 %  ┃\n",
      "┃          26  ┃      0.2276  │     85.20 %  ┃   8.734e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.4380  │     86.91 %  ┃\n",
      "┃          27  ┃      0.2171  │     87.14 %  ┃   8.622e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.4451  │     85.08 %  ┃\n",
      "┃          28  ┃      0.2139  │     87.07 %  ┃   8.506e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.4273  │     87.17 %  ┃\n",
      "┃          29  ┃      0.2084  │     88.55 %  ┃   8.387e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.4227  │     85.34 %  ┃\n",
      "┃          30  ┃      0.1986  │     88.61 %  ┃   8.263e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.4100  │     87.43 %  ┃\n",
      "┃          31  ┃      0.2011  │     88.08 %  ┃   8.136e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.4144  │     86.91 %  ┃\n",
      "┃          32  ┃      0.1964  │     88.81 %  ┃   8.006e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.4048  │     87.43 %  ┃\n",
      "┃          33  ┃      0.1942  │     90.09 %  ┃   7.872e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.4056  │     87.17 %  ┃\n",
      "┃          34  ┃      0.1930  │     90.15 %  ┃   7.735e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3957  │     88.22 %  ┃\n",
      "┃          35  ┃      0.1883  │     90.15 %  ┃   7.595e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3890  │     89.53 %  ┃\n",
      "┃          36  ┃      0.1850  │     90.76 %  ┃   7.452e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3919  │     89.53 %  ┃\n",
      "┃          37  ┃      0.1809  │     91.63 %  ┃   7.307e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3746  │     89.01 %  ┃\n",
      "┃          38  ┃      0.1805  │     91.29 %  ┃   7.159e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3829  │     88.74 %  ┃\n",
      "┃          39  ┃      0.1774  │     91.69 %  ┃   7.009e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3778  │     88.22 %  ┃\n",
      "┃          40  ┃      0.1748  │     92.10 %  ┃   6.856e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3895  │     88.48 %  ┃\n",
      "┃          41  ┃      0.1729  │     92.30 %  ┃   6.702e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3846  │     89.53 %  ┃\n",
      "┃          42  ┃      0.1715  │     92.90 %  ┃   6.545e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3708  │     90.31 %  ┃\n",
      "┃          43  ┃      0.1714  │     91.96 %  ┃   6.387e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3775  │     90.31 %  ┃\n",
      "┃          44  ┃      0.1699  │     92.83 %  ┃   6.228e-04  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.3644  │     89.79 %  ┃\n",
      "┃          45  ┃      0.1707  │     92.16 %  ┃   6.067e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3619  │     89.53 %  ┃\n",
      "┃          46  ┃      0.1653  │     93.57 %  ┃   5.905e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3577  │     91.88 %  ┃\n",
      "┃          47  ┃      0.1660  │     93.17 %  ┃   5.742e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3672  │     90.31 %  ┃\n",
      "┃          48  ┃      0.1611  │     93.90 %  ┃   5.578e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3623  │     89.79 %  ┃\n",
      "┃          49  ┃      0.1638  │     92.63 %  ┃   5.413e-04  │   12:55 min  ┃┈██████████████████████████▓┈┨      0.3567  │     89.27 %  ┃\n",
      "┃          50  ┃      0.1622  │     93.84 %  ┃   5.248e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3610  │     90.84 %  ┃\n",
      "┃          51  ┃      0.1578  │     93.37 %  ┃   5.083e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3619  │     90.05 %  ┃\n",
      "┃          52  ┃      0.1573  │     93.90 %  ┃   4.918e-04  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.3616  │     89.53 %  ┃\n",
      "┃          53  ┃      0.1579  │     93.50 %  ┃   4.752e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3477  │     91.36 %  ┃\n",
      "┃          54  ┃      0.1564  │     94.31 %  ┃   4.587e-04  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.3533  │     90.31 %  ┃\n",
      "┃          55  ┃      0.1553  │     93.97 %  ┃   4.423e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3626  │     90.31 %  ┃\n",
      "┃          56  ┃      0.1548  │     94.11 %  ┃   4.259e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3562  │     90.84 %  ┃\n",
      "┃          57  ┃      0.1529  │     94.37 %  ┃   4.096e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3526  │     90.84 %  ┃\n",
      "┃          58  ┃      0.1514  │     94.64 %  ┃   3.934e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3572  │     91.62 %  ┃\n",
      "┃          59  ┃      0.1507  │     94.31 %  ┃   3.773e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3473  │     91.36 %  ┃\n",
      "┃          60  ┃      0.1501  │     94.91 %  ┃   3.613e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3521  │     91.36 %  ┃\n",
      "┃          61  ┃      0.1504  │     94.98 %  ┃   3.455e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3406  │     92.41 %  ┃\n",
      "┃          62  ┃      0.1459  │     95.58 %  ┃   3.299e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3525  │     91.62 %  ┃\n",
      "┃          63  ┃      0.1484  │     95.24 %  ┃   3.144e-04  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.3495  │     91.62 %  ┃\n",
      "┃          64  ┃      0.1481  │     94.91 %  ┃   2.992e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3479  │     92.15 %  ┃\n",
      "┃          65  ┃      0.1461  │     95.45 %  ┃   2.841e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3398  │     92.15 %  ┃\n",
      "┃          66  ┃      0.1443  │     95.31 %  ┃   2.693e-04  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.3502  │     91.88 %  ┃\n",
      "┃          67  ┃      0.1410  │     95.65 %  ┃   2.548e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3516  │     91.36 %  ┃\n",
      "┃          68  ┃      0.1411  │     95.51 %  ┃   2.405e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3415  │     91.62 %  ┃\n",
      "┃          69  ┃      0.1423  │     95.85 %  ┃   2.265e-04  │   12:51 min  ┃┈██████████████████████████▓┈┨      0.3476  │     91.62 %  ┃\n",
      "┃          70  ┃      0.1401  │     96.18 %  ┃   2.129e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3346  │     91.62 %  ┃\n",
      "┃          71  ┃      0.1391  │     95.71 %  ┃   1.995e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3384  │     92.41 %  ┃\n",
      "┃          72  ┃      0.1373  │     96.52 %  ┃   1.864e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3443  │     91.62 %  ┃\n",
      "┃          73  ┃      0.1361  │     96.25 %  ┃   1.737e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3347  │     92.41 %  ┃\n",
      "┃          74  ┃      0.1373  │     96.45 %  ┃   1.614e-04  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3364  │     92.93 %  ┃\n",
      "┃          75  ┃      0.1348  │     96.25 %  ┃   1.494e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3365  │     92.67 %  ┃\n",
      "┃          76  ┃      0.1341  │     96.38 %  ┃   1.378e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3374  │     91.62 %  ┃\n",
      "┃          77  ┃      0.1356  │     96.18 %  ┃   1.266e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3287  │     92.93 %  ┃\n",
      "┃          78  ┃      0.1337  │     96.45 %  ┃   1.158e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3425  │     91.10 %  ┃\n",
      "┃          79  ┃      0.1323  │     96.78 %  ┃   1.054e-04  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3253  │     93.19 %  ┃\n",
      "┃          80  ┃      0.1327  │     96.58 %  ┃   9.550e-05  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.3309  │     92.67 %  ┃\n",
      "┃          81  ┃      0.1327  │     96.65 %  ┃   8.601e-05  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3238  │     92.15 %  ┃\n",
      "┃          82  ┃      0.1329  │     96.78 %  ┃   7.696e-05  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3319  │     92.41 %  ┃\n",
      "┃          83  ┃      0.1331  │     96.72 %  ┃   6.838e-05  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.3348  │     91.62 %  ┃\n",
      "┃          84  ┃      0.1307  │     96.92 %  ┃   6.027e-05  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3324  │     93.46 %  ┃\n",
      "┃          85  ┃      0.1308  │     96.85 %  ┃   5.265e-05  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3311  │     92.93 %  ┃\n",
      "┃          86  ┃      0.1299  │     97.05 %  ┃   4.551e-05  │   12:55 min  ┃┈██████████████████████████▓┈┨      0.3274  │     92.67 %  ┃\n",
      "┃          87  ┃      0.1316  │     97.12 %  ┃   3.886e-05  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3280  │     93.19 %  ┃\n",
      "┃          88  ┃      0.1309  │     97.19 %  ┃   3.273e-05  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3283  │     92.15 %  ┃\n",
      "┃          89  ┃      0.1293  │     97.12 %  ┃   2.710e-05  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.3318  │     93.19 %  ┃\n",
      "┃          90  ┃      0.1314  │     97.05 %  ┃   2.199e-05  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3286  │     92.93 %  ┃\n",
      "┃          91  ┃      0.1292  │     97.19 %  ┃   1.740e-05  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3300  │     92.67 %  ┃\n",
      "┃          92  ┃      0.1285  │     97.19 %  ┃   1.334e-05  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3334  │     93.19 %  ┃\n",
      "┃          93  ┃      0.1279  │     97.19 %  ┃   9.814e-06  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3307  │     92.93 %  ┃\n",
      "┃          94  ┃      0.1294  │     97.25 %  ┃   6.823e-06  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3332  │     92.41 %  ┃\n",
      "┃          95  ┃      0.1305  │     97.12 %  ┃   4.371e-06  │   12:53 min  ┃┈██████████████████████████▓┈┨      0.3281  │     93.19 %  ┃\n",
      "┃          96  ┃      0.1292  │     97.19 %  ┃   2.461e-06  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3299  │     93.46 %  ┃\n",
      "┃          97  ┃      0.1300  │     96.92 %  ┃   1.095e-06  │   12:52 min  ┃┈██████████████████████████▓┈┨      0.3309  │     92.93 %  ┃\n",
      "┃          98  ┃      0.1292  │     96.92 %  ┃   2.741e-07  │   12:54 min  ┃┈██████████████████████████▓┈┨      0.3300  │     92.67 %  ┃\n",
      "┃          99  ┃      0.1291  │     97.19 %  ┃   4.899e-13  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.3329  │     92.67 %  ┃\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saving_epochs = list(range(epochs))\n",
    "\n",
    "best_pred = 0\n",
    "\n",
    "print(\"Starting from epoch {}\".format(epoch_checkpoint))\n",
    "for epoch in range(epoch_checkpoint, epochs):\n",
    "    model.train()\n",
    "    log.train(len_dataset=len(dataloader_train))\n",
    "    \n",
    "    for ix, batch in enumerate(dataloader_train):\n",
    "        scheduler(optimizer, ix, epoch, best_pred)\n",
    "        inputs, targets = (b.to(device) for b in batch)\n",
    "        predictions = model(inputs)\n",
    "        loss = criterion(predictions, targets)\n",
    "        loss.mean().backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "        # second forward-backward step\n",
    "        # disable_bn(model)\n",
    "        criterion(model(inputs), targets).mean().backward()\n",
    "        # enable_bn(model)\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = torch.argmax(predictions.data, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu(), optimizer.param_groups[0][\"lr\"])\n",
    "                \n",
    "    model.eval()\n",
    "    log.eval(len_dataset=len(dataloader_valid))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader_valid:\n",
    "            inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, targets)\n",
    "            correct = torch.argmax(predictions, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu())\n",
    "            \n",
    "    if epoch in saving_epochs:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            }, os.path.join(checkpoint_dir, \"checkpoint_model7_\" + str(fold_id) + \"_\" + str(epoch) + \".pth\")\n",
    "        )\n",
    "\n",
    "log.flush()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
