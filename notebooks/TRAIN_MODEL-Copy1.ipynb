{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL IMPORTS AND PARAMETERS ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "from models_scripts import i3_res50, i3_res50_nl, disable_bn, enable_bn\n",
    "from utilities_scripts import SAM, LR_Scheduler, get_criterion, LoadingBar, Log, initialize, RandAugment\n",
    "from dataset_scripts import CTDataset\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "cuda_device_index = 1\n",
    "rho = 0.05\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.005\n",
    "warmup_epochs = 5\n",
    "epochs = 150\n",
    "n_class = 2 # extend number of classes\n",
    "fold_id = \"1\" #the current fold running\n",
    "root = \"/home/sentic/storage2/iccv_madu/fold_1\"\n",
    "num_workers = 2 # workers for dataloader\n",
    "fold_train_path = \"./train_folding.json\"\n",
    "fold_valid_path = \"./valid_folding.json\"\n",
    "checkpoint_dir = \"/home/sentic/storage2/iccv_madu/checkpoints/\"\n",
    "# checkpoint_dir = \"/home/sentic/Documents/data/storage2/LEUKEMIA/C-NMC_Leukemia/checkpoints/\"\n",
    "device = torch.device(\"cuda:\" + str(cuda_device_index) if torch.cuda.is_available() else \"cpu\")\n",
    "prepath = \"\"\n",
    "# replacer = \"/home/sentic/Documents/data/storage2/LEUKEMIA/C-NMC_Leukemia\"\n",
    "replacer = \"\"\n",
    "clip_len = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL STUFF ###\n",
    "#### I) ResNet50_3D_NL ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I3Res50(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool1): MaxPool3d(kernel_size=(2, 3, 3), stride=(2, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "  (maxpool2): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(256, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (nl): NonLocalBlock(\n",
       "        (theta): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (maxpool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "        (phi): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (g): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (out): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (nl): NonLocalBlock(\n",
       "        (theta): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (maxpool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "        (phi): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (g): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (out): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (nl): NonLocalBlock(\n",
       "        (theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (maxpool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "        (phi): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (g): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (out): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (nl): NonLocalBlock(\n",
       "        (theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (maxpool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "        (phi): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (g): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (out): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (nl): NonLocalBlock(\n",
       "        (theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (maxpool): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
       "        (phi): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (g): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (out): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained = None\n",
    "\n",
    "model = i3_res50_nl(n_class)\n",
    "\n",
    "if pretrained is not None:\n",
    "    model.load_state_dict(torch.load(pretrained, map_location='cuda:' + str(cuda_device_index)))\n",
    "\n",
    "\n",
    "######################\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET STUFF ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fold_train_path) as fhandle:\n",
    "    fold_splitter_train = json.load(fhandle)\n",
    "    \n",
    "with open(fold_valid_path) as fhandle:\n",
    "    fold_splitter_valid = json.load(fhandle)\n",
    "    \n",
    "dataset_train = CTDataset(root=root, \n",
    "                      fold_id=fold_id, \n",
    "                      fold_splitter=fold_splitter_train,\n",
    "                      transforms=None,\n",
    "                      replacer=\"\",\n",
    "                      prepath=\"\",\n",
    "                      clip_len=clip_len,\n",
    "                      split=\"train\"\n",
    "                      )\n",
    "\n",
    "dataset_valid = CTDataset(root=root, \n",
    "                      fold_id=fold_id, \n",
    "                      fold_splitter=fold_splitter_valid,\n",
    "                      transforms=None,\n",
    "                      replacer=\"\",\n",
    "                      prepath=\"\",\n",
    "                      clip_len=clip_len,\n",
    "                      split=\"val\"\n",
    "                      )\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=1, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKPOINTING MODEL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECKPOINTING ###\n",
    "#checkpoint = \"/home/sentic/storage2/iccv_madu/checkpoints/checkpoint_model1_1_17.pth\"\n",
    "checkpoint = None\n",
    "\n",
    "epoch_checkpoint = None\n",
    "net_state_dict = None\n",
    "optimizer_state_dict = None\n",
    "\n",
    "if checkpoint is not None:\n",
    "    dict_checkpoint = torch.load(checkpoint)\n",
    "    epoch_checkpoint = dict_checkpoint['epoch'] + 1\n",
    "    net_state_dict = dict_checkpoint['model_state_dict']\n",
    "    optimizer_state_dict = dict_checkpoint['optimizer_state_dict']\n",
    "    print(\"Initializing from checkpoint\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "if net_state_dict is not None:\n",
    "    model.load_state_dict(net_state_dict)\n",
    "    print(\"Loading model weights from checkpoint\")\n",
    "    \n",
    "if epoch_checkpoint is not None:\n",
    "    if epoch_checkpoint > warmup_epochs:\n",
    "        warmup_epochs = 0\n",
    "    else:\n",
    "        warmup_epochs = warmup_epochs - epoch_checkpoint\n",
    "    print(\"Setting warmup_epochs to {}\".format(warmup_epochs))\n",
    "\n",
    "if epoch_checkpoint is None:\n",
    "    epoch_checkpoint = 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTILS STUFF ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_optimizer = torch.optim.SGD\n",
    "optimizer = SAM(model.parameters(), base_optimizer, rho=rho, lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "if optimizer_state_dict is not None:\n",
    "    optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "scheduler = LR_Scheduler('cos',\n",
    "                        base_lr=learning_rate,\n",
    "                        num_epochs=epochs - epoch_checkpoint,\n",
    "                        iters_per_epoch=len(dataloader_train),\n",
    "                        warmup_epochs=warmup_epochs)\n",
    "\n",
    "criterion = get_criterion(smooth=0.1)\n",
    "log = Log(log_each=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN LOOP with CHECKPOINTING OPTIMIZER ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from epoch 0\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━╸T╺╸R╺╸A╺╸I╺╸N╺━━━━━━━┳━━━━━━━╸S╺╸T╺╸A╺╸T╺╸S╺━━━━━━━┳━━━━━━━╸V╺╸A╺╸L╺╸I╺╸D╺━━━━━━━┓\n",
      "┃              ┃              ╷              ┃              ╷              ┃              ╷              ┃\n",
      "┃       epoch  ┃        loss  │    accuracy  ┃        l.r.  │     elapsed  ┃        loss  │    accuracy  ┃\n",
      "┠──────────────╂──────────────┼──────────────╂──────────────┼──────────────╂──────────────┼──────────────┨\n",
      "\n",
      "┃           0  ┃      0.3457  │     54.77 %  ┃   1.997e-04  │   13:04 min  ┃┈██████████████████████████▓┈┨      0.7023  │     55.59 %  ┃\n",
      "┃           1  ┃      0.3415  │     57.10 %  ┃   3.997e-04  │   13:06 min  ┃┈██████████████████████████▓┈┨      0.6794  │     55.59 %  ┃\n",
      "┃           2  ┃      0.3420  │     55.50 %  ┃   5.997e-04  │   13:06 min  ┃┈██████████████████████████▓┈┨      0.6811  │     55.59 %  ┃\n",
      "┃           3  ┃      0.3431  │     55.37 %  ┃   7.997e-04  │   13:06 min  ┃┈██████████████████████████▓┈┨      0.6840  │     55.59 %  ┃\n",
      "┃           4  ┃      0.3434  │     55.31 %  ┃   9.997e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.6850  │     55.59 %  ┃\n",
      "┃           5  ┃      0.3436  │     55.31 %  ┃   9.999e-04  │   13:04 min  ┃┈██████████████████████████▓┈┨      0.6841  │     55.59 %  ┃\n",
      "┃           6  ┃      0.3425  │     55.31 %  ┃   9.995e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.6823  │     55.59 %  ┃\n",
      "┃           7  ┃      0.3406  │     56.50 %  ┃   9.989e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.6721  │     61.04 %  ┃\n",
      "┃           8  ┃      0.3337  │     63.86 %  ┃   9.981e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.6459  │     65.94 %  ┃\n",
      "┃           9  ┃      0.3169  │     70.16 %  ┃   9.971e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.5894  │     76.84 %  ┃\n",
      "┃          10  ┃      0.2997  │     74.27 %  ┃   9.958e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.5846  │     73.30 %  ┃\n",
      "┃          11  ┃      0.2842  │     76.92 %  ┃   9.943e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.5435  │     78.47 %  ┃\n",
      "┃          12  ┃      0.2691  │     78.91 %  ┃   9.925e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.5189  │     79.02 %  ┃\n",
      "┃          13  ┃      0.2544  │     82.69 %  ┃   9.905e-04  │   13:06 min  ┃┈██████████████████████████▓┈┨      0.4894  │     80.11 %  ┃\n",
      "┃          14  ┃      0.2406  │     84.08 %  ┃   9.883e-04  │   13:07 min  ┃┈██████████████████████████▓┈┨      0.4666  │     82.29 %  ┃\n",
      "┃          15  ┃      0.2272  │     86.01 %  ┃   9.859e-04  │   13:08 min  ┃┈██████████████████████████▓┈┨      0.4631  │     81.20 %  ┃\n",
      "┃          16  ┃      0.2162  │     87.20 %  ┃   9.832e-04  │   13:07 min  ┃┈██████████████████████████▓┈┨      0.4535  │     82.29 %  ┃\n",
      "┃          17  ┃      0.2102  │     87.67 %  ┃   9.803e-04  │   13:08 min  ┃┈██████████████████████████▓┈┨      0.4566  │     82.29 %  ┃\n",
      "┃          18  ┃      0.2056  │     87.80 %  ┃   9.772e-04  │   13:07 min  ┃┈██████████████████████████▓┈┨      0.4577  │     82.83 %  ┃\n",
      "┃          19  ┃      0.2034  │     88.13 %  ┃   9.738e-04  │   13:06 min  ┃┈██████████████████████████▓┈┨      0.4538  │     83.38 %  ┃\n",
      "┃          20  ┃      0.1917  │     89.92 %  ┃   9.703e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.4318  │     84.74 %  ┃\n",
      "┃          21  ┃      0.1921  │     89.92 %  ┃   9.665e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.4372  │     84.20 %  ┃\n",
      "┃          22  ┃      0.1891  │     90.78 %  ┃   9.625e-04  │   13:04 min  ┃┈██████████████████████████▓┈┨      0.4175  │     84.74 %  ┃\n",
      "┃          23  ┃      0.1878  │     90.19 %  ┃   9.582e-04  │   13:04 min  ┃┈██████████████████████████▓┈┨      0.4135  │     86.10 %  ┃\n",
      "┃          24  ┃      0.1827  │     90.52 %  ┃   9.538e-04  │   13:04 min  ┃┈██████████████████████████▓┈┨      0.4133  │     85.56 %  ┃\n",
      "┃          25  ┃      0.1799  │     91.64 %  ┃   9.491e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.4127  │     84.74 %  ┃\n",
      "┃          26  ┃      0.1801  │     91.25 %  ┃   9.443e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.3974  │     85.29 %  ┃\n",
      "┃          27  ┃      0.1759  │     91.64 %  ┃   9.392e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.3971  │     88.01 %  ┃\n",
      "┃          28  ┃      0.1722  │     92.44 %  ┃   9.339e-04  │   13:06 min  ┃┈██████████████████████████▓┈┨      0.3956  │     87.19 %  ┃\n",
      "┃          29  ┃      0.1692  │     92.77 %  ┃   9.284e-04  │   13:09 min  ┃┈██████████████████████████▓┈┨      0.3977  │     87.19 %  ┃\n",
      "┃          30  ┃      0.1704  │     92.57 %  ┃   9.228e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.4023  │     87.19 %  ┃\n",
      "┃          31  ┃      0.1681  │     92.84 %  ┃   9.169e-04  │   13:03 min  ┃┈██████████████████████████▓┈┨      0.3892  │     88.28 %  ┃\n",
      "┃          32  ┃      0.1684  │     92.57 %  ┃   9.108e-04  │   13:03 min  ┃┈██████████████████████████▓┈┨      0.3809  │     86.92 %  ┃\n",
      "┃          33  ┃      0.1669  │     92.31 %  ┃   9.045e-04  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.3912  │     86.65 %  ┃\n",
      "┃          34  ┃      0.1671  │     93.04 %  ┃   8.981e-04  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.4059  │     84.74 %  ┃\n",
      "┃          35  ┃      0.1629  │     93.44 %  ┃   8.914e-04  │   13:02 min  ┃┈██████████████████████████▓┈┨      0.3896  │     87.19 %  ┃\n",
      "┃          36  ┃      0.1655  │     93.10 %  ┃   8.846e-04  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.3886  │     86.65 %  ┃\n",
      "┃          37  ┃      0.1633  │     93.44 %  ┃   8.776e-04  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.3873  │     86.65 %  ┃\n",
      "┃          38  ┃      0.1591  │     93.97 %  ┃   8.704e-04  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.3858  │     86.10 %  ┃\n",
      "┃          39  ┃      0.1596  │     93.63 %  ┃   8.630e-04  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.3743  │     89.37 %  ┃\n",
      "┃          40  ┃      0.1591  │     93.90 %  ┃   8.555e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.3794  │     88.56 %  ┃\n",
      "┃          41  ┃      0.1577  │     94.30 %  ┃   8.478e-04  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.3788  │     87.47 %  ┃\n",
      "┃          42  ┃      0.1592  │     93.97 %  ┃   8.399e-04  │   12:57 min  ┃┈██████████████████████████▓┈┨      0.3718  │     87.74 %  ┃\n",
      "┃          43  ┃      0.1582  │     94.03 %  ┃   8.319e-04  │   12:57 min  ┃┈██████████████████████████▓┈┨      0.3914  │     87.19 %  ┃\n",
      "┃          44  ┃      0.1558  │     94.56 %  ┃   8.237e-04  │   12:57 min  ┃┈██████████████████████████▓┈┨      0.3899  │     86.38 %  ┃\n",
      "┃          45  ┃      0.1585  │     93.70 %  ┃   8.154e-04  │   12:57 min  ┃┈██████████████████████████▓┈┨      0.3723  │     87.74 %  ┃\n",
      "┃          46  ┃      0.1592  │     94.30 %  ┃   8.069e-04  │   12:57 min  ┃┈██████████████████████████▓┈┨      0.3779  │     87.74 %  ┃\n",
      "┃          47  ┃      0.1600  │     93.57 %  ┃   7.983e-04  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.3825  │     87.74 %  ┃\n",
      "┃          48  ┃      0.1581  │     93.63 %  ┃   7.895e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.3931  │     87.19 %  ┃\n",
      "┃          49  ┃      0.1558  │     94.23 %  ┃   7.806e-04  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.3809  │     87.74 %  ┃\n",
      "┃          50  ┃      0.1554  │     93.97 %  ┃   7.716e-04  │   12:57 min  ┃┈██████████████████████████▓┈┨      0.3844  │     88.56 %  ┃\n",
      "┃          51  ┃      0.1577  │     93.97 %  ┃   7.624e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.3878  │     86.65 %  ┃\n",
      "┃          52  ┃      0.1574  │     94.03 %  ┃   7.531e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4325  │     85.29 %  ┃\n",
      "┃          53  ┃      0.1672  │     92.51 %  ┃   7.437e-04  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.4068  │     85.01 %  ┃\n",
      "┃          54  ┃      0.1715  │     92.57 %  ┃   7.342e-04  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.4015  │     86.10 %  ┃\n",
      "┃          55  ┃      0.1648  │     93.37 %  ┃   7.246e-04  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.3785  │     88.28 %  ┃\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┃          56  ┃      0.1666  │     92.51 %  ┃   7.149e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4204  │     85.29 %  ┃\n",
      "┃          57  ┃      0.1628  │     93.44 %  ┃   7.050e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.3878  │     86.92 %  ┃\n",
      "┃          58  ┃      0.1719  │     91.64 %  ┃   6.951e-04  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.4177  │     85.01 %  ┃\n",
      "┃          59  ┃      0.1681  │     93.10 %  ┃   6.851e-04  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.3944  │     87.47 %  ┃\n",
      "┃          60  ┃      0.1693  │     93.24 %  ┃   6.750e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4015  │     86.38 %  ┃\n",
      "┃          61  ┃      0.1657  │     92.64 %  ┃   6.648e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4025  │     86.65 %  ┃\n",
      "┃          62  ┃      0.1739  │     91.51 %  ┃   6.545e-04  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.4112  │     86.10 %  ┃\n",
      "┃          63  ┃      0.1701  │     91.98 %  ┃   6.442e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4031  │     84.74 %  ┃\n",
      "┃          64  ┃      0.1689  │     92.84 %  ┃   6.338e-04  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.4053  │     87.47 %  ┃\n",
      "┃          65  ┃      0.1655  │     93.24 %  ┃   6.233e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.3996  │     88.28 %  ┃\n",
      "┃          66  ┃      0.1730  │     92.44 %  ┃   6.128e-04  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.4271  │     84.20 %  ┃\n",
      "┃          67  ┃      0.1711  │     92.57 %  ┃   6.022e-04  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.4048  │     86.92 %  ┃\n",
      "┃          68  ┃      0.1748  │     91.78 %  ┃   5.916e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4044  │     85.29 %  ┃\n",
      "┃          69  ┃      0.1747  │     91.64 %  ┃   5.809e-04  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.4147  │     86.10 %  ┃\n",
      "┃          70  ┃      0.1650  │     93.10 %  ┃   5.702e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.3921  │     87.74 %  ┃\n",
      "┃          71  ┃      0.1681  │     92.64 %  ┃   5.595e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4106  │     88.28 %  ┃\n",
      "┃          72  ┃      0.1693  │     92.97 %  ┃   5.487e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4441  │     82.56 %  ┃\n",
      "┃          73  ┃      0.1705  │     92.64 %  ┃   5.379e-04  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.4104  │     87.19 %  ┃\n",
      "┃          74  ┃      0.1650  │     92.90 %  ┃   5.271e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4420  │     86.92 %  ┃\n",
      "┃          75  ┃      0.1691  │     92.37 %  ┃   5.163e-04  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.4023  │     88.01 %  ┃\n",
      "┃          76  ┃      0.1694  │     92.31 %  ┃   5.054e-04  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.4110  │     86.10 %  ┃\n",
      "┃          77  ┃      0.1729  │     92.18 %  ┃   4.946e-04  │   12:57 min  ┃┈██████████████████████████▓┈┨      0.3904  │     87.19 %  ┃\n",
      "┃          78  ┃      0.1700  │     93.10 %  ┃   4.838e-04  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.4054  │     86.38 %  ┃\n",
      "┃          79  ┃      0.1688  │     92.77 %  ┃   4.729e-04  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.3940  │     87.47 %  ┃\n",
      "┃          80  ┃      0.1610  │     93.83 %  ┃   4.621e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.3845  │     87.19 %  ┃\n",
      "┃          81  ┃      0.1636  │     92.64 %  ┃   4.513e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4343  │     84.20 %  ┃\n",
      "┃          82  ┃      0.1612  │     93.83 %  ┃   4.406e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4053  │     87.47 %  ┃\n",
      "┃          83  ┃      0.1617  │     94.03 %  ┃   4.298e-04  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.4035  │     87.74 %  ┃\n",
      "┃          84  ┃      0.1637  │     93.97 %  ┃   4.191e-04  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.4062  │     88.01 %  ┃\n",
      "┃          85  ┃      0.1651  │     93.37 %  ┃   4.085e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.3752  │     88.56 %  ┃\n",
      "┃          86  ┃      0.1603  │     93.70 %  ┃   3.978e-04  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.4244  │     85.29 %  ┃\n",
      "┃          87  ┃      0.1627  │     93.30 %  ┃   3.872e-04  │   12:58 min  ┃┈██████████████████████████▓┈┨      0.4190  │     86.10 %  ┃\n",
      "┃          88  ┃      0.1620  │     93.24 %  ┃   3.767e-04  │   13:20 min  ┃┈██████████████████████████▓┈┨      0.3830  │     88.28 %  ┃\n",
      "┃          89  ┃      0.1632  │     93.10 %  ┃   3.662e-04  │   16:11 min  ┃┈██████████████████████████▓┈┨      0.4029  │     86.92 %  ┃\n",
      "┃          90  ┃      0.1603  │     93.90 %  ┃   3.558e-04  │   13:08 min  ┃┈██████████████████████████▓┈┨      0.4218  │     84.74 %  ┃\n",
      "┃          91  ┃      0.1563  │     94.43 %  ┃   3.455e-04  │   13:09 min  ┃┈██████████████████████████▓┈┨      0.3802  │     89.37 %  ┃\n",
      "┃          92  ┃      0.1598  │     94.30 %  ┃   3.352e-04  │   13:21 min  ┃┈██████████████████████████▓┈┨      0.3861  │     87.19 %  ┃\n",
      "┃          93  ┃      0.1583  │     94.03 %  ┃   3.251e-04  │   13:35 min  ┃┈██████████████████████████▓┈┨      0.3916  │     87.47 %  ┃\n",
      "┃          94  ┃      0.1601  │     93.83 %  ┃   3.149e-04  │   14:19 min  ┃┈██████████████████████████▓┈┨      0.3807  │     89.92 %  ┃\n",
      "┃          95  ┃      0.1560  │     94.23 %  ┃   3.049e-04  │   15:39 min  ┃┈██████████████████████████▓┈┨      0.4000  │     88.56 %  ┃\n",
      "┃          96  ┃      0.1563  │     94.43 %  ┃   2.950e-04  │   13:15 min  ┃┈██████████████████████████▓┈┨      0.4029  │     87.74 %  ┃\n",
      "┃          97  ┃      0.1555  │     94.43 %  ┃   2.852e-04  │   13:10 min  ┃┈██████████████████████████▓┈┨      0.3948  │     87.74 %  ┃\n",
      "┃          98  ┃      0.1529  │     95.23 %  ┃   2.754e-04  │   13:09 min  ┃┈██████████████████████████▓┈┨      0.3814  │     89.65 %  ┃\n",
      "┃          99  ┃      0.1525  │     94.83 %  ┃   2.658e-04  │   13:10 min  ┃┈██████████████████████████▓┈┨      0.3770  │     88.01 %  ┃\n",
      "┃         100  ┃      0.1630  │     93.70 %  ┃   2.563e-04  │   13:09 min  ┃┈██████████████████████████▓┈┨      0.3852  │     87.74 %  ┃\n",
      "┃         101  ┃      0.1630  │     93.50 %  ┃   2.469e-04  │   13:10 min  ┃┈██████████████████████████▓┈┨      0.3762  │     88.83 %  ┃\n",
      "┃         102  ┃      0.1568  │     94.30 %  ┃   2.376e-04  │   13:12 min  ┃┈██████████████████████████▓┈┨      0.3804  │     87.74 %  ┃\n",
      "┃         103  ┃      0.1563  │     94.10 %  ┃   2.285e-04  │   13:10 min  ┃┈██████████████████████████▓┈┨      0.4006  │     86.10 %  ┃\n",
      "┃         104  ┃      0.1562  │     94.10 %  ┃   2.194e-04  │   13:11 min  ┃┈██████████████████████████▓┈┨      0.3867  │     88.83 %  ┃\n",
      "┃         105  ┃      0.1533  │     94.30 %  ┃   2.105e-04  │   13:02 min  ┃┈██████████████████████████▓┈┨      0.3743  │     89.65 %  ┃\n",
      "┃         106  ┃      0.1520  │     94.69 %  ┃   2.018e-04  │   17:27 min  ┃┈██████████████████████████▓┈┨      0.3613  │     90.19 %  ┃\n",
      "┃         107  ┃      0.1531  │     94.56 %  ┃   1.931e-04  │   20:19 min  ┃┈██████████████████████████▓┈┨      0.3810  │     89.92 %  ┃\n",
      "┃         108  ┃      0.1500  │     95.03 %  ┃   1.846e-04  │   23:02 min  ┃┈██████████████████████████▓┈┨      0.3700  │     90.46 %  ┃\n",
      "┃         109  ┃      0.1486  │     95.36 %  ┃   1.763e-04  │   21:36 min  ┃┈██████████████████████████▓┈┨      0.3601  │     90.19 %  ┃\n",
      "┃         110  ┃      0.1491  │     94.96 %  ┃   1.681e-04  │   14:14 min  ┃┈██████████████████████████▓┈┨      0.3756  │     90.19 %  ┃\n",
      "┃         111  ┃      0.1466  │     95.29 %  ┃   1.601e-04  │   20:58 min  ┃┈██████████████████████████▓┈┨      0.3763  │     88.83 %  ┃\n",
      "┃         112  ┃      0.1513  │     94.76 %  ┃   1.522e-04  │   18:34 min  ┃┈██████████████████████████▓┈┨      0.3664  │     89.10 %  ┃\n",
      "┃         113  ┃      0.1480  │     95.42 %  ┃   1.445e-04  │   18:46 min  ┃┈██████████████████████████▓┈┨      0.3917  │     87.47 %  ┃\n",
      "┃         114  ┃      0.1461  │     95.23 %  ┃   1.370e-04  │   19:04 min  ┃┈██████████████████████████▓┈┨      0.3784  │     89.10 %  ┃\n",
      "┃         115  ┃      0.1462  │     95.36 %  ┃   1.296e-04  │   17:32 min  ┃┈██████████████████████████▓┈┨      0.3663  │     89.92 %  ┃\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┃         116  ┃      0.1452  │     95.36 %  ┃   1.225e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.3608  │     90.46 %  ┃\n",
      "┃         117  ┃      0.1439  │     95.82 %  ┃   1.154e-04  │   13:05 min  ┃┈██████████████████████████▓┈┨      0.3653  │     90.19 %  ┃\n",
      "┃         118  ┃      0.1423  │     96.22 %  ┃   1.086e-04  │   13:09 min  ┃┈██████████████████████████▓┈┨      0.3634  │     89.92 %  ┃\n",
      "┃         119  ┃      0.1414  │     95.95 %  ┃   1.020e-04  │   13:10 min  ┃┈██████████████████████████▓┈┨      0.3725  │     90.46 %  ┃\n",
      "┃         120  ┃      0.1404  │     96.42 %  ┃   9.550e-05  │   13:09 min  ┃┈██████████████████████████▓┈┨      0.3611  │     90.46 %  ┃\n",
      "┃         121  ┃      0.1404  │     96.42 %  ┃   8.923e-05  │   13:03 min  ┃┈██████████████████████████▓┈┨      0.3698  │     90.19 %  ┃\n",
      "┃         122  ┃      0.1421  │     95.76 %  ┃   8.315e-05  │   13:02 min  ┃┈██████████████████████████▓┈┨      0.3666  │     89.65 %  ┃\n",
      "┃         123  ┃      0.1401  │     95.95 %  ┃   7.726e-05  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.3690  │     89.65 %  ┃\n",
      "┃         124  ┃      0.1400  │     96.35 %  ┃   7.158e-05  │   16:25 min  ┃┈██████████████████████████▓┈┨      0.3696  │     89.65 %  ┃\n",
      "┃         125  ┃      0.1382  │     96.68 %  ┃   6.609e-05  │   13:04 min  ┃┈██████████████████████████▓┈┨      0.3577  │     90.74 %  ┃\n",
      "┃         126  ┃      0.1387  │     96.42 %  ┃   6.081e-05  │   13:02 min  ┃┈██████████████████████████▓┈┨      0.3699  │     90.46 %  ┃\n",
      "┃         127  ┃      0.1382  │     96.15 %  ┃   5.574e-05  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.3585  │     90.46 %  ┃\n",
      "┃         128  ┃      0.1390  │     96.35 %  ┃   5.087e-05  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.3671  │     89.92 %  ┃\n",
      "┃         129  ┃      0.1367  │     96.62 %  ┃   4.622e-05  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.3579  │     90.19 %  ┃\n",
      "┃         130  ┃      0.1371  │     96.75 %  ┃   4.178e-05  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.3520  │     91.28 %  ┃\n",
      "┃         131  ┃      0.1360  │     96.68 %  ┃   3.755e-05  │   13:00 min  ┃┈██████████████████████████▓┈┨      0.3679  │     90.74 %  ┃\n",
      "┃         132  ┃      0.1363  │     96.88 %  ┃   3.354e-05  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.3727  │     89.92 %  ┃\n",
      "┃         133  ┃      0.1364  │     96.55 %  ┃   2.975e-05  │   13:01 min  ┃┈██████████████████████████▓┈┨      0.3581  │     90.19 %  ┃\n",
      "┃         134  ┃      0.1370  │     97.02 %  ┃   2.618e-05  │   12:59 min  ┃┈██████████████████████████▓┈┨      0.3683  │     90.74 %  ┃\n",
      "┃         135  ┃      0.1365  │     96.49 %  ┃   2.283e-05  │   12:57 min  ┃┈██████████████████████████▓┈┨      0.3727  │     90.46 %  ┃\n",
      "┃         136  ┃      0.1368  │     96.42 %  ┃   1.971e-05  │   12:57 min  ┃┈██████████████████████████▓┈┨      0.3497  │     91.83 %  ┃\n",
      "┃         137  ┃      0.1368  │     96.75 %  ┃   1.681e-05  │   12:57 min  ┃┈██████████████████████████▓┈┨      0.3526  │     89.92 %  ┃\n",
      "┃         138  ┃      0.1356  │     96.88 %  ┃   1.414e-05  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3566  │     89.92 %  ┃\n",
      "┃         139  ┃      0.1369  │     96.49 %  ┃   1.169e-05  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3560  │     89.37 %  ┃\n",
      "┃         140  ┃      0.1370  │     96.15 %  ┃   9.479e-06  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3638  │     90.46 %  ┃\n",
      "┃         141  ┃      0.1346  │     96.68 %  ┃   7.494e-06  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3509  │     91.28 %  ┃\n",
      "┃         142  ┃      0.1317  │     97.08 %  ┃   5.742e-06  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3573  │     90.19 %  ┃\n",
      "┃         143  ┃      0.1356  │     96.82 %  ┃   4.221e-06  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3632  │     89.92 %  ┃\n",
      "┃         144  ┃      0.1371  │     96.09 %  ┃   2.933e-06  │   12:55 min  ┃┈██████████████████████████▓┈┨      0.3636  │     89.65 %  ┃\n",
      "┃         145  ┃      0.1363  │     96.68 %  ┃   1.878e-06  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3595  │     90.74 %  ┃\n",
      "┃         146  ┃      0.1353  │     96.95 %  ┃   1.057e-06  │   12:55 min  ┃┈██████████████████████████▓┈┨      0.3607  │     90.46 %  ┃\n",
      "┃         147  ┃      0.1354  │     96.88 %  ┃   4.700e-07  │   12:56 min  ┃┈██████████████████████████▓┈┨      0.3636  │     89.92 %  ┃\n",
      "┃         148  ┃      0.1353  │     97.35 %  ┃   1.177e-07  │   12:55 min  ┃┈██████████████████████████▓┈┨      0.3605  │     89.10 %  ┃\n",
      "┃         149  ┃      0.1357  │     96.88 %  ┃   2.064e-13  │   12:55 min  ┃┈██████████████████████████▓┈┨      0.3641  │     90.74 %  ┃\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saving_epochs = list(range(epochs))\n",
    "\n",
    "best_pred = 0\n",
    "\n",
    "print(\"Starting from epoch {}\".format(epoch_checkpoint))\n",
    "for epoch in range(epoch_checkpoint, epochs):\n",
    "    model.train()\n",
    "    log.train(len_dataset=len(dataloader_train))\n",
    "    \n",
    "    for ix, batch in enumerate(dataloader_train):\n",
    "        scheduler(optimizer, ix, epoch, best_pred)\n",
    "        inputs, targets = (b.to(device) for b in batch)\n",
    "        predictions = model(inputs)\n",
    "        loss = criterion(predictions, targets)\n",
    "        loss.mean().backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "        # second forward-backward step\n",
    "        # disable_bn(model)\n",
    "        criterion(model(inputs), targets).mean().backward()\n",
    "        # enable_bn(model)\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = torch.argmax(predictions.data, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu(), optimizer.param_groups[0][\"lr\"])\n",
    "                \n",
    "    model.eval()\n",
    "    log.eval(len_dataset=len(dataloader_valid))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader_valid:\n",
    "            inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, targets)\n",
    "            correct = torch.argmax(predictions, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu())\n",
    "            \n",
    "    if epoch in saving_epochs:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            }, os.path.join(checkpoint_dir, \"checkpoint_model1_150_\" + str(fold_id) + \"_\" + str(epoch) + \".pth\")\n",
    "        )\n",
    "\n",
    "log.flush()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
