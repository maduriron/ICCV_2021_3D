{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ FOR LEUKEMIA ################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(\"UID_([h|H]?\\d+)_(\\d+)_(\\d+)_(\\w+).bmp\")\n",
    "mapper = {\"hem\": 0,\n",
    "         \"all\": 1}\n",
    "\n",
    "def extract_patient_metadata(path, regex=regex, mapper=mapper):\n",
    "    metadata = re.findall(regex, path)\n",
    "    patient_id = 0\n",
    "    image_number = 0\n",
    "    cell_count = 0\n",
    "    label = 0\n",
    "    \n",
    "    if len(metadata) > 0:\n",
    "        patient_id = metadata[0][0]\n",
    "        image_number = metadata[0][1]\n",
    "        cell_count = metadata[0][2]\n",
    "        label = mapper[metadata[0][3]]\n",
    "    else:\n",
    "        print(\"Unable to access for path {}\".format(path))\n",
    "    \n",
    "    return {\"patient_id\": patient_id, \n",
    "           \"image_number\": image_number,\n",
    "           \"cell_number\": cell_count,\n",
    "           \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\"\"\"\n",
    "fold_splitter := {\"fold_id0\": {\"paths\": [<<list of paths>>], \"metadata\": [<<list of metadata>>]},\n",
    "                  \"fold_id1\": {\"paths\": [<<list of paths>>], \"metadata\": [<<list of metadata>>]},\n",
    "                        ...\n",
    "                }\n",
    "\"\"\"\n",
    "\n",
    "fold_splitter_train = {\"1\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"2\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"3\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"4\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"5\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"6\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"7\": {\"paths\": [],\n",
    "                      \"metadata\": []},\n",
    "                }\n",
    "\n",
    "fold_splitter_val = {\"1\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"2\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"3\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"4\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"5\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"6\": {\"paths\": [],\n",
    "                      \"metadata\": []}, \n",
    "                 \"7\": {\"paths\": [],\n",
    "                      \"metadata\": []},\n",
    "                }\n",
    "\n",
    "\n",
    "folding = {\"1\": [\"50\", \"19\", \"35\", \"49\", \"72\", \"31\",\n",
    "                 \"H24\", \"H7\", \"H16\"],\n",
    "           \"2\": [\"45\", \"4\", \"26\", \"43\", \"20\", \"21\",\n",
    "                \"H19\", \"H12\", \"H11\", \"H1\", \"h3\"],\n",
    "           \"3\": [\"11\", \"74\", \"67\", \"24\", \"18\", \"25\",\n",
    "                \"H23\", \"H20\"],\n",
    "           \"4\": [\"28\", \"17\", \"5\", \"14\", \"52\",\n",
    "                \"H8\", \"H9\", \"H48\", \"H13\", \"H2\"],\n",
    "           \"5\": [\"36\", \"37\", \"68\", \"75\", \"78\",\n",
    "                \"H18\", \"H5\", \"H46\", \"H23\"],\n",
    "           \"6\": [\"47\", \"27\", \"22\", \"38\", \"30\",\n",
    "                \"H2\", \"H14\"],\n",
    "           \"7\": [\"48\", \"13\", \"15\", \"3\", \"1\", \"2\", \"33\",\n",
    "                \"H22\", \"H4\", \"H6\"]\n",
    "          }\n",
    "dir_data = \"/home/sentic/Documents/data/storage2/LEUKEMIA/C-NMC_Leukemia/C-NMC_training_data/\"\n",
    "\n",
    "\"\"\"\n",
    "dir\n",
    "    fold_ix\n",
    "        all -> images\n",
    "        hem -> images\n",
    "\"\"\"\n",
    "range_folds = [\"0\", \"1\", \"2\"]\n",
    "classes = [\"all\", \"hem\"]\n",
    "\n",
    "d = {}\n",
    "\n",
    "for ix_fold in range_folds:\n",
    "    dir_fold = os.path.join(dir_data, \"fold_\" + ix_fold)\n",
    "    for class_name in classes:\n",
    "        dir_final = os.path.join(dir_fold, class_name)\n",
    "        for im_name in os.listdir(dir_final):\n",
    "            full_path = os.path.join(dir_final, im_name)\n",
    "            metadata = extract_patient_metadata(im_name)\n",
    "            if metadata[\"patient_id\"] not in d:\n",
    "                d[metadata['patient_id']] = {\"image_number\": [],\n",
    "                                 \"cell_number\": [],\n",
    "                                 \"label\": []}\n",
    "            d[metadata['patient_id']]['image_number'].append( metadata['image_number'])\n",
    "            d[metadata['patient_id']]['cell_number'].append( metadata['cell_number'])\n",
    "            d[metadata['patient_id']]['label'].append( metadata['label'])\n",
    "            \n",
    "            found = 0\n",
    "            for ix_split in fold_splitter_val:\n",
    "                if metadata[\"patient_id\"] in folding[ix_split]:\n",
    "                    fold_splitter_val[ix_split][\"paths\"].append(full_path)\n",
    "                    fold_splitter_val[ix_split][\"metadata\"].append(metadata)\n",
    "                else:\n",
    "                    fold_splitter_train[ix_split][\"paths\"].append(full_path)\n",
    "                    fold_splitter_train[ix_split][\"metadata\"].append(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## FOR CTs ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "mapper = {\"non-covid\": 0,\n",
    "         \"covid\": 1}\n",
    "\n",
    "\n",
    "regex = re.compile(\"/([^/]*)/ct_scan_(\\d+)\")\n",
    "\n",
    "def extract_patient_metadata(path, regex=regex, mapper=mapper):\n",
    "    metadata = re.findall(regex, path)\n",
    "    patient_id = 0\n",
    "    label = 0\n",
    "    \n",
    "    if len(metadata) > 0:\n",
    "        patient_id = int(metadata[0][1])\n",
    "        label = mapper[metadata[0][0]]\n",
    "    else:\n",
    "        print(\"Unable to access for path {}\".format(path))\n",
    "    \n",
    "    return {\"patient_id\": patient_id,\n",
    "           \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_splitter_train = {\"1\": {\"paths\": [],\n",
    "                            \"metadata\": [],\n",
    "                            \"frames\": []}, \n",
    "                }\n",
    "\n",
    "fold_splitter_valid = {\"1\": {\"paths\": [],\n",
    "                            \"metadata\": [],\n",
    "                            \"frames\": []}, \n",
    "                }\n",
    "\n",
    "ix_fold = 1\n",
    "total_folds = 1\n",
    "dir_data = \"/home/sentic/storage2/iccv_madu/\"\n",
    "\n",
    "while ix_fold <= total_folds:\n",
    "    fold_path = os.path.join(dir_data, \"fold_\" + str(ix_fold))\n",
    "    \n",
    "    fold_path_train = os.path.join(fold_path, \"train\")\n",
    "    fold_path_valid = os.path.join(fold_path, \"val\")\n",
    "    \n",
    "    fold_path_train_covid = os.path.join(fold_path_train, \"covid\")\n",
    "    fold_path_train_noncovid = os.path.join(fold_path_train, \"non-covid\")\n",
    "    \n",
    "    fold_path_valid_covid = os.path.join(fold_path_valid, \"covid\")\n",
    "    fold_path_valid_noncovid = os.path.join(fold_path_valid, \"non-covid\")\n",
    "    \n",
    "    for fname in os.listdir(fold_path_train_covid):\n",
    "        full_path = os.path.join(fold_path_train_covid, fname)\n",
    "        fold_splitter_train[str(ix_fold)][\"paths\"].append(full_path)\n",
    "        fold_splitter_train[str(ix_fold)][\"metadata\"].append(1) # is covid |-> label := 1\n",
    "        fold_splitter_train[str(ix_fold)][\"frames\"].append(len(os.listdir(full_path)))\n",
    "        \n",
    "    for fname in os.listdir(fold_path_train_noncovid):\n",
    "        full_path = os.path.join(fold_path_train_noncovid, fname)\n",
    "        fold_splitter_train[str(ix_fold)][\"paths\"].append(full_path)\n",
    "        fold_splitter_train[str(ix_fold)][\"metadata\"].append(0) # is non-covid |-> label := 1\n",
    "        fold_splitter_train[str(ix_fold)][\"frames\"].append(len(os.listdir(full_path)))\n",
    "        \n",
    "    for fname in os.listdir(fold_path_valid_covid):\n",
    "        full_path = os.path.join(fold_path_valid_covid, fname)\n",
    "        fold_splitter_valid[str(ix_fold)][\"paths\"].append(full_path)\n",
    "        fold_splitter_valid[str(ix_fold)][\"metadata\"].append(1) # is covid |-> label := 1\n",
    "        fold_splitter_valid[str(ix_fold)][\"frames\"].append(len(os.listdir(full_path)))\n",
    "        \n",
    "    for fname in os.listdir(fold_path_valid_noncovid):\n",
    "        full_path = os.path.join(fold_path_valid_noncovid, fname)\n",
    "        fold_splitter_valid[str(ix_fold)][\"paths\"].append(full_path)\n",
    "        fold_splitter_valid[str(ix_fold)][\"metadata\"].append(0) # is non-covid |-> label := 1\n",
    "        fold_splitter_valid[str(ix_fold)][\"frames\"].append(len(os.listdir(full_path)))\n",
    "    \n",
    "    ix_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./train_folding.json\", \"w\") as fhandle:\n",
    "    json.dump(fold_splitter_train, fhandle)\n",
    "    \n",
    "with open(\"./valid_folding.json\", \"w\") as fhandle:\n",
    "    json.dump(fold_splitter_valid, fhandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./train_folding.json\", \"r\") as fhandle:\n",
    "    fold_splitter_train = json.load(fhandle)\n",
    "    \n",
    "with open(\"./valid_folding.json\", \"r\") as fhandle:\n",
    "    fold_splitter_valid = json.load(fhandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## SHUFFLE IN ORDER TO  MAKE NEW FOLDS ##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I) Make sure you don t put in valid what you already had some previous fold\n",
    "# II) Sample from the training fold to create the distribution in the valid dataset\n",
    "#   bin    |   val covid    |  val non-covid |\n",
    "#_________________________________________________\n",
    "#  20/120   |     77        |       117      |\n",
    "#  120/240  |     13        |        9       |\n",
    "#  240/360  |     47        |       76       |\n",
    "#  360/480  |     27        |       30       |\n",
    "#  480/600  |     2         |        6       |\n",
    "#  600/*    |     1         |        1       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_in_valid = []\n",
    "\n",
    "for ix_fold in fold_splitter_valid:\n",
    "    already_in_valid += fold_splitter_valid[ix_fold][\"paths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_training_paths = fold_splitter_train[\"1\"][\"paths\"]\n",
    "initial_training_labels = fold_splitter_train[\"1\"][\"metadata\"]\n",
    "initial_training_frames = fold_splitter_train[\"1\"][\"frames\"]\n",
    "\n",
    "initial_valid_paths = fold_splitter_valid[\"1\"][\"paths\"]\n",
    "initial_valid_labels = fold_splitter_valid[\"1\"][\"metadata\"]\n",
    "initial_valid_frames = fold_splitter_valid[\"1\"][\"frames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "covid_1 = [(p, l, f) for (p, l, f) in zip(initial_training_paths, initial_training_labels, initial_training_frames)\n",
    "          if l == 1 and 20 <= f and f < 120]\n",
    "\n",
    "covid_2 = [(p, l, f) for (p, l, f) in zip(initial_training_paths, initial_training_labels, initial_training_frames)\n",
    "          if l == 1 and 120 <= f and f < 240]\n",
    "\n",
    "covid_3 = [(p, l, f) for (p, l, f) in zip(initial_training_paths, initial_training_labels, initial_training_frames)\n",
    "          if l == 1 and 240 <= f and f < 360]\n",
    "\n",
    "covid_4 = [(p, l, f) for (p, l, f) in zip(initial_training_paths, initial_training_labels, initial_training_frames)\n",
    "          if l == 1 and 360 <= f and f < 480]\n",
    "\n",
    "covid_5 = [(p, l, f) for (p, l, f) in zip(initial_training_paths, initial_training_labels, initial_training_frames)\n",
    "          if l == 1 and 480 <= f and f < 512]\n",
    "###########################################################################################################\n",
    "non_covid_1 = [(p, l, f) for (p, l, f) in zip(initial_training_paths, initial_training_labels, initial_training_frames)\n",
    "          if l == 0 and 20 <= f and f < 120]\n",
    "\n",
    "non_covid_2 = [(p, l, f) for (p, l, f) in zip(initial_training_paths, initial_training_labels, initial_training_frames)\n",
    "          if l == 0 and 120 <= f and f < 240]\n",
    "\n",
    "non_covid_3 = [(p, l, f) for (p, l, f) in zip(initial_training_paths, initial_training_labels, initial_training_frames)\n",
    "          if l == 0 and 240 <= f and f < 360]\n",
    "\n",
    "non_covid_4 = [(p, l, f) for (p, l, f) in zip(initial_training_paths, initial_training_labels, initial_training_frames)\n",
    "          if l == 0 and 360 <= f and f < 480]\n",
    "\n",
    "non_covid_5 = [(p, l, f) for (p, l, f) in zip(initial_training_paths, initial_training_labels, initial_training_frames)\n",
    "          if l == 0 and 480 <= f and f < 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(covid_1))\n",
    "# print(len(covid_2))\n",
    "# print(len(covid_3))\n",
    "# print(len(covid_4))\n",
    "# print(len(covid_5))\n",
    "# print(\"\\n##################\\n\")\n",
    "# print(len(non_covid_1))\n",
    "# print(len(non_covid_2))\n",
    "# print(len(non_covid_3))\n",
    "# print(len(non_covid_4))\n",
    "# print(len(non_covid_5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "list_splits = [covid_1, covid_2, covid_3, covid_4, covid_5,\n",
    "               non_covid_1, non_covid_2, non_covid_3, non_covid_4, non_covid_5]\n",
    "constraints = {\"1\": 74, \"2\": 8, \"3\": 56, \"4\": 28, \"5\": 2, # covid distribution \n",
    "               \"6\": 107, \"7\": 13, \"8\": 60, \"9\": 29, \"10\": 5 # non-covid distribution\n",
    "                }\n",
    "new_fold_idxs = [\"2\", \"3\", \"4\", \"5\"]\n",
    "\n",
    "for enum_ix_fold, new_fold_idx in enumerate(new_fold_idxs):\n",
    "    fold_splitter_train[new_fold_idx] = {\"paths\": [],\n",
    "                                        \"metadata\": [],\n",
    "                                        \"frames\": []}\n",
    "    fold_splitter_valid[new_fold_idx] = {\"paths\": [],\n",
    "                                        \"metadata\": [],\n",
    "                                        \"frames\": []}\n",
    "    for ix, sample in enumerate(list_splits):\n",
    "        num_from_sample = constraints[str(ix + 1)]\n",
    "        to_add_in_val = random.sample(sample, num_from_sample)\n",
    "        fold_splitter_valid[new_fold_idx][\"paths\"] += [p for (p, _, _) in to_add_in_val]\n",
    "        fold_splitter_valid[new_fold_idx][\"metadata\"] += [l for (_, l, _) in to_add_in_val]\n",
    "        fold_splitter_valid[new_fold_idx][\"frames\"] += [f for (_, _, f) in to_add_in_val]\n",
    "        \n",
    "        #print(len(fold_splitter_train[new_fold_idx][\"paths\"]))\n",
    "        \n",
    "        fold_splitter_train[new_fold_idx][\"paths\"] += [p for (p, l, f) in sample if (p, l, f) not in to_add_in_val]\n",
    "        fold_splitter_train[new_fold_idx][\"metadata\"] += [l for (p, l, f) in sample if (p, l, f) not in to_add_in_val]\n",
    "        fold_splitter_train[new_fold_idx][\"frames\"] += [f for (p, l, f) in sample if (p, l, f) not in to_add_in_val]        \n",
    "\n",
    "    fold_splitter_train[new_fold_idx][\"paths\"] += [p for p in initial_valid_paths]\n",
    "    fold_splitter_train[new_fold_idx][\"metadata\"] += [l for l in initial_valid_labels]\n",
    "    fold_splitter_train[new_fold_idx][\"frames\"] += [f for f in initial_valid_frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./train_folding.json\", \"w\") as fhandle:\n",
    "    json.dump(fold_splitter_train, fhandle)\n",
    "    \n",
    "with open(\"./valid_folding.json\", \"w\") as fhandle:\n",
    "    json.dump(fold_splitter_valid, fhandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### MAKING TEST FOLD ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_splitter_test = {\"1\": {\"paths\": [],\n",
    "                            \"metadata\": [],\n",
    "                            \"frames\": []}, \n",
    "                }\n",
    "dir_test_imags = \"/home/sentic/storage2/iccv_test_madu\"\n",
    "import os\n",
    "\n",
    "for dir_name in os.listdir(dir_test_imags):\n",
    "    fold_splitter_test[\"1\"][\"paths\"].append(os.path.join(dir_test_imags, dir_name))\n",
    "    fold_splitter_test[\"1\"][\"metadata\"].append(2)\n",
    "    fold_splitter_test[\"1\"][\"frames\"].append(len(os.listdir(os.path.join(dir_test_imags, dir_name))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./test_set_folding.json\", \"w\") as fhandle:\n",
    "    json.dump(fold_splitter_test, fhandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
