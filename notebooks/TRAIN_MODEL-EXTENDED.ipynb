{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL IMPORTS AND PARAMETERS ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "from models_scripts import i3_res50, i3_res50_nl, disable_bn, enable_bn\n",
    "from utilities_scripts import SAM, LR_Scheduler, get_criterion, LoadingBar, Log, initialize, RandAugment\n",
    "from dataset_scripts import CTDataset\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "cuda_device_index = 0\n",
    "rho = 0.05\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.005\n",
    "warmup_epochs = 5\n",
    "epochs = 60\n",
    "n_class = 2 # extend number of classes\n",
    "fold_id = \"1\" #the current fold running\n",
    "root = \"/home/sentic/storage2/iccv_madu/fold_1\"\n",
    "num_workers = 2 # workers for dataloader\n",
    "fold_train_path = \"./train_folding_extended.json\"\n",
    "fold_valid_path = \"./valid_folding.json\"\n",
    "checkpoint_dir = \"/home/sentic/storage2/iccv_madu/checkpoints/\"\n",
    "# checkpoint_dir = \"/home/sentic/Documents/data/storage2/LEUKEMIA/C-NMC_Leukemia/checkpoints/\"\n",
    "device = torch.device(\"cuda:\" + str(cuda_device_index) if torch.cuda.is_available() else \"cpu\")\n",
    "prepath = \"\"\n",
    "# replacer = \"/home/sentic/Documents/data/storage2/LEUKEMIA/C-NMC_Leukemia\"\n",
    "replacer = \"\"\n",
    "clip_len = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL STUFF ###\n",
    "#### I) ResNet50_3D_NL ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = \"/home/sentic/storage2/iccv_madu/checkpoints/model1_basicAUG_fold1_1/checkpoint_model1_150_1_141.pth\"\n",
    "\n",
    "dict_pretrained = torch.load(pretrained, map_location='cuda:' + str(cuda_device_index))\n",
    "net_state_dict = dict_pretrained['model_state_dict']\n",
    "\n",
    "model = i3_res50_nl(n_class)\n",
    "\n",
    "if pretrained is not None:\n",
    "    model.load_state_dict(net_state_dict)\n",
    "\n",
    "\n",
    "######################\n",
    "model.to(device)\n",
    "\n",
    "######################\n",
    "del net_state_dict\n",
    "del dict_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET STUFF ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fold_train_path) as fhandle:\n",
    "    fold_splitter_train = json.load(fhandle)\n",
    "    \n",
    "with open(fold_valid_path) as fhandle:\n",
    "    fold_splitter_valid = json.load(fhandle)\n",
    "    \n",
    "dataset_train = CTDataset(root=root, \n",
    "                      fold_id=fold_id, \n",
    "                      fold_splitter=fold_splitter_train,\n",
    "                      transforms=None,\n",
    "                      replacer=\"\",\n",
    "                      prepath=\"\",\n",
    "                      clip_len=clip_len,\n",
    "                      split=\"train\"\n",
    "                      )\n",
    "\n",
    "dataset_valid = CTDataset(root=root, \n",
    "                      fold_id=fold_id, \n",
    "                      fold_splitter=fold_splitter_valid,\n",
    "                      transforms=None,\n",
    "                      replacer=\"\",\n",
    "                      prepath=\"\",\n",
    "                      clip_len=clip_len,\n",
    "                      split=\"val\"\n",
    "                      )\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=1, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKPOINTING MODEL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECKPOINTING ###\n",
    "#checkpoint = \"/home/sentic/storage2/iccv_madu/checkpoints/checkpoint_model1_1_17.pth\"\n",
    "checkpoint = None\n",
    "\n",
    "epoch_checkpoint = None\n",
    "net_state_dict = None\n",
    "optimizer_state_dict = None\n",
    "\n",
    "if checkpoint is not None:\n",
    "    dict_checkpoint = torch.load(checkpoint)\n",
    "    epoch_checkpoint = dict_checkpoint['epoch'] + 1\n",
    "    net_state_dict = dict_checkpoint['model_state_dict']\n",
    "    optimizer_state_dict = dict_checkpoint['optimizer_state_dict']\n",
    "    print(\"Initializing from checkpoint\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "if net_state_dict is not None:\n",
    "    model.load_state_dict(net_state_dict)\n",
    "    print(\"Loading model weights from checkpoint\")\n",
    "    \n",
    "if epoch_checkpoint is not None:\n",
    "    if epoch_checkpoint > warmup_epochs:\n",
    "        warmup_epochs = 0\n",
    "    else:\n",
    "        warmup_epochs = warmup_epochs - epoch_checkpoint\n",
    "    print(\"Setting warmup_epochs to {}\".format(warmup_epochs))\n",
    "\n",
    "if epoch_checkpoint is None:\n",
    "    epoch_checkpoint = 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTILS STUFF ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_optimizer = torch.optim.SGD\n",
    "optimizer = SAM(model.parameters(), base_optimizer, rho=rho, lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "if optimizer_state_dict is not None:\n",
    "    optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "scheduler = LR_Scheduler('cos',\n",
    "                        base_lr=learning_rate,\n",
    "                        num_epochs=epochs - epoch_checkpoint,\n",
    "                        iters_per_epoch=len(dataloader_train),\n",
    "                        warmup_epochs=warmup_epochs)\n",
    "\n",
    "criterion = get_criterion(smooth=0.1)\n",
    "log = Log(log_each=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN LOOP with CHECKPOINTING OPTIMIZER ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from epoch 0\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━╸T╺╸R╺╸A╺╸I╺╸N╺━━━━━━━┳━━━━━━━╸S╺╸T╺╸A╺╸T╺╸S╺━━━━━━━┳━━━━━━━╸V╺╸A╺╸L╺╸I╺╸D╺━━━━━━━┓\n",
      "┃              ┃              ╷              ┃              ╷              ┃              ╷              ┃\n",
      "┃       epoch  ┃        loss  │    accuracy  ┃        l.r.  │     elapsed  ┃        loss  │    accuracy  ┃\n",
      "┠──────────────╂──────────────┼──────────────╂──────────────┼──────────────╂──────────────┼──────────────┨\n",
      "\n",
      "┃           0  ┃      0.1315  │     97.45 %  ┃   1.998e-05  │   47:44 min  ┃┈███████████████████████████┈┨      0.3588  │     90.46 %  ┃\n",
      "┃           1  ┃      0.1319  │     97.34 %  ┃   3.998e-05  │   57:36 min  ┃┈███████████████████████████┈┨      0.3576  │     89.65 %  ┃\n",
      "┃           2  ┃      0.1324  │     97.23 %  ┃   5.998e-05  │   40:21 min  ┃┈███████████████████████████┈┨      0.3652  │     91.01 %  ┃\n",
      "┃           3  ┃      0.1332  │     97.00 %  ┃   7.998e-05  │   46:57 min  ┃┈███████████████████████████┈┨      0.3534  │     90.46 %  ┃\n",
      "┃           4  ┃      0.1339  │     97.11 %  ┃   9.998e-05  │   28:15 min  ┃┈███████████████████████████┈┨      0.3722  │     90.19 %  ┃\n",
      "┃           5  ┃      0.1347  │     96.84 %  ┃   9.992e-05  │   18:36 min  ┃┈███████████████████████████┈┨      0.3639  │     89.92 %  ┃\n",
      "┃           6  ┃      0.1346  │     97.11 %  ┃   9.967e-05  │   21:24 min  ┃┈███████████████████████████┈┨      0.3628  │     89.10 %  ┃\n",
      "┃           7  ┃      0.1332  │     97.23 %  ┃   9.927e-05  │   15:57 min  ┃┈███████████████████████████┈┨      0.3516  │     90.46 %  ┃\n",
      "┃           8  ┃      0.1349  │     96.67 %  ┃   9.870e-05  │   21:53 min  ┃┈███████████████████████████┈┨      0.3605  │     89.65 %  ┃\n",
      "┃           9  ┃      0.1329  │     97.17 %  ┃   9.798e-05  │   30:24 min  ┃┈███████████████████████████┈┨      0.3660  │     89.92 %  ┃\n",
      "┃          10  ┃      0.1345  │     96.95 %  ┃   9.709e-05  │   25:03 min  ┃┈███████████████████████████┈┨      0.3467  │     91.28 %  ┃\n",
      "┃          11  ┃      0.1340  │     96.67 %  ┃   9.606e-05  │   15:55 min  ┃┈███████████████████████████┈┨      0.3621  │     90.74 %  ┃\n",
      "┃          12  ┃      0.1325  │     97.34 %  ┃   9.487e-05  │   15:55 min  ┃┈███████████████████████████┈┨      0.3616  │     90.19 %  ┃\n",
      "┃          13  ┃      0.1339  │     96.56 %  ┃   9.354e-05  │   21:45 min  ┃┈███████████████████████████┈┨      0.3639  │     89.65 %  ┃\n",
      "┃          14  ┃      0.1343  │     97.06 %  ┃   9.206e-05  │   32:53 min  ┃┈███████████████████████████┈┨      0.3579  │     89.92 %  ┃\n",
      "┃          15  ┃      0.1336  │     97.17 %  ┃   9.045e-05  │   18:15 min  ┃┈███████████████████████████┈┨      0.3519  │     91.01 %  ┃\n",
      "┃          16  ┃      0.1326  │     97.28 %  ┃   8.871e-05  │   15:57 min  ┃┈███████████████████████████┈┨      0.3612  │     90.46 %  ┃\n",
      "┃          17  ┃      0.1322  │     97.17 %  ┃   8.684e-05  │   15:58 min  ┃┈███████████████████████████┈┨      0.3483  │     90.74 %  ┃\n",
      "┃          18  ┃      0.1323  │     97.28 %  ┃   8.485e-05  │   24:04 min  ┃┈███████████████████████████┈┨      0.3721  │     90.74 %  ┃\n",
      "┃          19  ┃      0.1314  │     97.61 %  ┃   8.275e-05  │   19:20 min  ┃┈███████████████████████████┈┨      0.3464  │     90.46 %  ┃\n",
      "┃          20  ┃      0.1304  │     97.45 %  ┃   8.053e-05  │   15:39 min  ┃┈███████████████████████████┈┨      0.3627  │     90.19 %  ┃\n",
      "┃          21  ┃      0.1298  │     97.56 %  ┃   7.822e-05  │   15:35 min  ┃┈███████████████████████████┈┨      0.3521  │     90.19 %  ┃\n",
      "┃          22  ┃      0.1304  │     97.45 %  ┃   7.582e-05  │   15:35 min  ┃┈███████████████████████████┈┨      0.3423  │     90.19 %  ┃\n",
      "┃          23  ┃      0.1300  │     97.39 %  ┃   7.334e-05  │   15:35 min  ┃┈███████████████████████████┈┨      0.3565  │     90.19 %  ┃\n",
      "┃          24  ┃      0.1316  │     96.84 %  ┃   7.077e-05  │   15:34 min  ┃┈███████████████████████████┈┨      0.3458  │     91.28 %  ┃\n",
      "┃          25  ┃      0.1301  │     97.11 %  ┃   6.814e-05  │   15:29 min  ┃┈███████████████████████████┈┨      0.3587  │     89.92 %  ┃\n",
      "┃          26  ┃      0.1301  │     97.06 %  ┃   6.545e-05  │   15:28 min  ┃┈███████████████████████████┈┨      0.3452  │     91.28 %  ┃\n",
      "┃          27  ┃      0.1306  │     97.28 %  ┃   6.271e-05  │   15:26 min  ┃┈███████████████████████████┈┨      0.3472  │     90.74 %  ┃\n",
      "┃          28  ┃      0.1287  │     97.39 %  ┃   5.993e-05  │   15:26 min  ┃┈███████████████████████████┈┨      0.3436  │     90.19 %  ┃\n",
      "┃          29  ┃      0.1296  │     97.45 %  ┃   5.712e-05  │   15:25 min  ┃┈███████████████████████████┈┨      0.3399  │     91.28 %  ┃\n",
      "┃          30  ┃      0.1305  │     97.23 %  ┃   5.428e-05  │   15:25 min  ┃┈███████████████████████████┈┨      0.3427  │     90.46 %  ┃\n",
      "┃          31  ┃      0.1281  │     97.39 %  ┃   5.143e-05  │   15:24 min  ┃┈███████████████████████████┈┨      0.3438  │     90.46 %  ┃\n",
      "┃          32  ┃      0.1314  │     97.45 %  ┃   4.858e-05  │   15:24 min  ┃┈███████████████████████████┈┨      0.3443  │     91.28 %  ┃\n",
      "┃          33  ┃      0.1304  │     97.17 %  ┃   4.572e-05  │   15:23 min  ┃┈███████████████████████████┈┨      0.3468  │     90.46 %  ┃\n",
      "┃          34  ┃      0.1294  │     97.34 %  ┃   4.289e-05  │   15:23 min  ┃┈███████████████████████████┈┨      0.3444  │     91.28 %  ┃\n",
      "┃          35  ┃      0.1295  │     97.39 %  ┃   4.007e-05  │   15:23 min  ┃┈███████████████████████████┈┨      0.3509  │     90.19 %  ┃\n",
      "┃          36  ┃      0.1272  │     97.50 %  ┃   3.729e-05  │   15:23 min  ┃┈███████████████████████████┈┨      0.3499  │     91.55 %  ┃\n",
      "┃          37  ┃      0.1286  │     97.56 %  ┃   3.455e-05  │   15:24 min  ┃┈███████████████████████████┈┨      0.3467  │     91.55 %  ┃\n",
      "┃          38  ┃      0.1283  │     97.56 %  ┃   3.186e-05  │   15:23 min  ┃┈███████████████████████████┈┨      0.3409  │     91.55 %  ┃\n",
      "┃          39  ┃      0.1283  │     97.45 %  ┃   2.923e-05  │   15:23 min  ┃┈███████████████████████████┈┨      0.3434  │     91.01 %  ┃\n",
      "┃          40  ┃      0.1264  │     97.72 %  ┃   2.667e-05  │   15:24 min  ┃┈███████████████████████████┈┨      0.3519  │     90.74 %  ┃\n",
      "┃          41  ┃      0.1267  │     97.72 %  ┃   2.418e-05  │   15:24 min  ┃┈███████████████████████████┈┨      0.3443  │     91.28 %  ┃\n",
      "┃          42  ┃      0.1266  │     97.78 %  ┃   2.178e-05  │   15:23 min  ┃┈███████████████████████████┈┨      0.3424  │     92.10 %  ┃\n",
      "┃          43  ┃      0.1268  │     97.67 %  ┃   1.947e-05  │   15:23 min  ┃┈███████████████████████████┈┨      0.3313  │     92.92 %  ┃\n",
      "┃          44  ┃      0.1268  │     97.61 %  ┃   1.726e-05  │   15:58 min  ┃┈███████████████████████████┈┨      0.3397  │     92.10 %  ┃\n",
      "┃          45  ┃      0.1260  │     97.72 %  ┃   1.516e-05  │   21:01 min  ┃┈███████████████████████████┈┨      0.3449  │     91.55 %  ┃\n",
      "┃          46  ┃      0.1268  │     97.56 %  ┃   1.317e-05  │   18:23 min  ┃┈███████████████████████████┈┨      0.3530  │     91.01 %  ┃\n",
      "┃          47  ┃      0.1273  │     97.56 %  ┃   1.129e-05  │   16:52 min  ┃┈███████████████████████████┈┨      0.3423  │     91.28 %  ┃\n",
      "┃          48  ┃      0.1276  │     97.50 %  ┃   9.551e-06  │   21:16 min  ┃┈███████████████████████████┈┨      0.3420  │     91.83 %  ┃\n",
      "┃          49  ┃      0.1255  │     97.72 %  ┃   7.939e-06  │   19:37 min  ┃┈███████████████████████████┈┨      0.3405  │     91.55 %  ┃\n",
      "┃          50  ┃      0.1260  │     97.61 %  ┃   6.464e-06  │   15:36 min  ┃┈███████████████████████████┈┨      0.3357  │     92.64 %  ┃\n",
      "┃          51  ┃      0.1274  │     97.50 %  ┃   5.131e-06  │   15:37 min  ┃┈███████████████████████████┈┨      0.3427  │     91.83 %  ┃\n",
      "┃          52  ┃      0.1266  │     97.45 %  ┃   3.945e-06  │   15:40 min  ┃┈███████████████████████████┈┨      0.3633  │     91.83 %  ┃\n",
      "┃          53  ┃      0.1264  │     97.56 %  ┃   2.909e-06  │   15:45 min  ┃┈███████████████████████████┈┨      0.3417  │     91.55 %  ┃\n",
      "┃          54  ┃      0.1263  │     97.78 %  ┃   2.026e-06  │   27:39 min  ┃┈███████████████████████████┈┨      0.3462  │     91.55 %  ┃\n",
      "┃          55  ┃      0.1272  │     97.39 %  ┃   1.300e-06  │   21:30 min  ┃┈███████████████████████████┈┨      0.3584  │     92.64 %  ┃\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┃          56  ┃      0.1269  │     97.61 %  ┃   7.328e-07  │   23:32 min  ┃┈███████████████████████████┈┨      0.3429  │     91.01 %  ┃\n",
      "┃          57  ┃      0.1256  │     97.78 %  ┃   3.263e-07  │   15:35 min  ┃┈███████████████████████████┈┨      0.3480  │     91.83 %  ┃\n",
      "┃          58  ┃      0.1263  │     97.50 %  ┃   8.173e-08  │   15:41 min  ┃┈███████████████████████████┈┨      0.3475  │     91.83 %  ┃\n",
      "┃          59  ┃      0.1271  │     97.45 %  ┃   1.005e-13  │   15:36 min  ┃┈███████████████████████████┈┨      0.3392  │     92.37 %  ┃\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saving_epochs = list(range(epochs))\n",
    "\n",
    "best_pred = 0\n",
    "\n",
    "print(\"Starting from epoch {}\".format(epoch_checkpoint))\n",
    "for epoch in range(epoch_checkpoint, epochs):\n",
    "    model.train()\n",
    "    log.train(len_dataset=len(dataloader_train))\n",
    "    \n",
    "    for ix, batch in enumerate(dataloader_train):\n",
    "        scheduler(optimizer, ix, epoch, best_pred)\n",
    "        inputs, targets = (b.to(device) for b in batch)\n",
    "        predictions = model(inputs)\n",
    "        loss = criterion(predictions, targets)\n",
    "        loss.mean().backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "        # second forward-backward step\n",
    "        criterion(model(inputs), targets).mean().backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = torch.argmax(predictions.data, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu(), optimizer.param_groups[0][\"lr\"])\n",
    "                \n",
    "    model.eval()\n",
    "    log.eval(len_dataset=len(dataloader_valid))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader_valid:\n",
    "            inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, targets)\n",
    "            correct = torch.argmax(predictions, 1) == targets\n",
    "            log(model, loss.cpu(), correct.cpu())\n",
    "            \n",
    "    if epoch in saving_epochs:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            }, os.path.join(checkpoint_dir, \"checkpoint_model8E_60_\" + str(fold_id) + \"_\" + str(epoch) + \".pth\")\n",
    "        )\n",
    "\n",
    "log.flush()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
